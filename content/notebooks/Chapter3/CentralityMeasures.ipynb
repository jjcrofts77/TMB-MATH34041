{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CentralityMeasures.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNO4/ZEXtmYj7R2Tf95DZNs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjcrofts77/TMB-MATH34041/blob/main/content/notebooks/Chapter3/CentralityMeasures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWs3lpIcH2Zv"
      },
      "source": [
        "# 3.1 Centrality Measures\n",
        "\n",
        "## Centrality measures\n",
        "Centrality measures provide a quantification of a nodes importance within a network, and thus provide a ranking of the networks nodes, such as that employed by Google to rank webpages. Amazingly, the same ideas that makes Google the worlds number one search engine are also being used in the battle against complex diseases: centrality measures have recently highlighted, for example, the p53 gene as playing a major role in the onset of certain types of cancer.  \n",
        "\n",
        "### Degree Centrality\n",
        "The *degree centrality* refers to the degree and ranks nodes accordingly.\n",
        "\n",
        "$$\n",
        " k_i = \\sum_{j=1}^na_{ij} = (\\mathbf{1}^TA)_i = (A\\mathbf{1})_i.\n",
        "$$\n",
        "\n",
        "Here node $i$ is more central than node $j$ if $k_i>k_j$. Below we list some elementary facts about the degree centrality\n",
        "\n",
        "1. $k_i = (A^2)_{ii}$.\n",
        "2. $\\sum_{i=1}^nk_i = 2m$, where $m$ is the number of links.\n",
        "\n",
        "```{figure} ../../images/CentralityExample.png\n",
        "---\n",
        "height: 350px\n",
        "name: centrality1\n",
        "---\n",
        "A simple network on 5 nodes.\n",
        "```\n",
        "\n",
        "As an example consider the network in {numref}`centrality1`. The adjacency matrix of this network is given by\n",
        "\n",
        "$$\n",
        "A = \\left(\n",
        "      \\begin{array}{ccccc}\n",
        "      0 & 1 & 1 &0 & 0\\\\\n",
        "      1 & 0 & 1 &1 & 1\\\\\n",
        "      1 & 1 & 0 &0 & 0\\\\\n",
        "      0 & 1 & 0 &0 & 0\\\\\n",
        "      0 & 1 & 0 &0 & 0\\\\\n",
        "      \\end{array}\n",
        "      \\right)\n",
        "$$\n",
        "\n",
        "and the node degree vector by\n",
        "\n",
        "$$\n",
        "\\mathbf{k} = A\\mathbf{1} = \\left(\n",
        "      \\begin{array}{ccccc}\n",
        "      0 & 1 & 1 &0 & 0\\\\\n",
        "      1 & 0 & 1 &1 & 1\\\\\n",
        "      1 & 1 & 0 &0 & 0\\\\\n",
        "      0 & 1 & 0 &0 & 0\\\\\n",
        "      0 & 1 & 0 &0 & 0\\\\\n",
        "      \\end{array}\n",
        "      \\right)\n",
        "      \\left(\n",
        "      \\begin{array}{c}\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      \\end{array}\n",
        "      \\right)=\n",
        "            \\left(\n",
        "      \\begin{array}{c}\n",
        "      2 \\\\\n",
        "      4 \\\\\n",
        "      2 \\\\\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      \\end{array}\n",
        "      \\right).\n",
        "$$\n",
        "\n",
        "That is, the degree of the nodes are: $k(1)=k(3)=2, k(2)=4, k(4)=k(5)=1$, indicating that node 2 is the most central.\n",
        "\n",
        "\\\n",
        "**Exercise**: Generalise the above definition of degree centrality to directed networks.\n",
        "\n",
        "\\\n",
        "### Katz Centrality\n",
        "When ranking a network's nodes, degree centrality considers the influence of nearest-neighbours only. However, other factors often need to be taken into account, such as the nodes position in the network, or the `importance' of its neighbours, for example. Note that we can write the degree centrality (all be it in a rather artificial way) in terms of powers of the adjacency matrix as\n",
        "\n",
        "$$\n",
        " \\mathbf{k} = \\left[ \\left(A^0+A^1\\right)-I\\right]\\mathbf{1}.\n",
        "$$\n",
        "\n",
        "Now, to incorporate more global effects such as those mentioned previously we consider an extension of the above formula that includes higher powers of the adjacency matrix, weighted in such a way as to guarantee convergence, i.e.\n",
        "\n",
        "$$\n",
        " \\left(\\alpha^0A^0+\\alpha^{1}A^1+\\alpha^{2}A^2+\\cdots +\\alpha^{k}A^k+\\cdots\\right)\\mathbf{1}.\n",
        "$$\n",
        "\n",
        "Such an extension incorporates information not only from nearest neighbours, but all other network nodes also. Importantly, as well as guaranteeing convergence, the `attenuation' factor $\\alpha$ dampens the influence of more distant nodes: this makes sense, as although we want to include this additional information, we still expect that nearby nodes will be the most influential.\n",
        "\n",
        "It can be shown that the above power series converges to\n",
        "\n",
        "$$\n",
        " K_i = \\left[\\left(\\sum_{k=0}^\\infty{\\alpha^{k}A^k}\\right)\\mathbf{1}\\right]_i =\n",
        " \\left[\\left(I-\\alpha A\\right)^{-1}\\mathbf{1}\\right]_i.\n",
        "$$\n",
        "\n",
        "This index was introduced by Katz in 1953 and thus is popularly referred to as the *Katz centrality* of a node. Often, since the first term contains no information one considers the related quantity\n",
        "\n",
        "$$\n",
        " K_i = \\left\\{\\left[\\left(I-\\alpha A\\right)^{-1} - I \\right]\\mathbf{1}\\right\\}_i,\n",
        "$$\n",
        "\n",
        "as we did above for the degree centrality.\n",
        "\n",
        "The choice of the parameter $\\alpha$ has a significant influence on the results of applying the Katz centrality to rank a network's nodes. For small values of $\\alpha$ the contribution of paths (or more strictly walks) longer than one rapidly declines, thus Katz scores are mainly influenced by a node's immediate neighbourhood. For larger values of the damping factor, the Katz scores are influenced more widely by the network topology. Note that $\\alpha$ should be chosen in the range $(0,1/\\rho(A))$ in order for the above series to converge, where here $\\rho(A)$ denotes the spectral radius of the network adjacency matrix\n",
        "\n",
        "```{note}\n",
        "Recall that $\\rho(A) = \\max\\{|\\lambda_1|,|\\lambda_2|,\\ldots,|\\lambda_n|\\}$ where $\\lambda_i$ are the eigenvalues of the adjacency matrix $A$.\n",
        "```\n",
        "\n",
        "```{figure} ../../images/CentralityExample2.png\n",
        "---\n",
        "height: 350px\n",
        "name: centrality2\n",
        "---\n",
        "A directed network on 11 nodes.\n",
        "```\n",
        "\n",
        "{numref}`centrality2` shows an example of a directed network and below we provide the Katz centrality scores (strictly speaking the out-Katz centrality score) for $\\alpha = 0.15$ and $\\alpha = 0.85$ respectively.\n",
        "\n",
        "$$\n",
        " \\mathbf{K} = [1.24, 1.41, 1.41, 1.00, 1.33, \\mathbf{1.59}, 1.24, 1.41, 1.41, 1.18, 1.18]\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        " \\mathbf{K} = [58.35, 64.01, 64.01, 1.00, 7.52, \\mathbf{67.47}, 58.35, 64.01, 64.01, 6.67, 6.67].\n",
        "$$\n",
        "\n",
        "In both instances node 6 is found to be the most central node; however, the rankings do differ in that node 5 is deemed less important for the larger value of $\\alpha$. One potential issue that this example highlights is that network nodes can have equivalent centrality scores, although (a) this is less likely to happen for larger networks, and (b) we are typically interested in finding nodes with maximal centrality scores, rather than accurately ranking all network nodes. Note also, that Katz centrality estimates the relative status or ability for a node to influence a network and so whilst node 10 has many incoming links, its lack of out-going links results in a low Katz centrality score.\n",
        "\n",
        "\n",
        "### Eigenvector Centrality\n",
        "Related to the idea of the Katz centrality is that of *eigenvector centrality* which can be derived by considering the following variation of the Katz index:\n",
        "\n",
        "$$\n",
        " \\mathbf{e} = \\left(\\sum_{k=1}^\\infty\\alpha^{k-1}A^k\\right)\\mathbf{1}.\n",
        "$$\n",
        "\n",
        "Next, deploy the eigendecomposition of the adjacency matrix ($A = UDU^T$ - since $A$ is a real, symmetric matrix it admits an orthogonal decomposition) to obtain\n",
        "\n",
        "$$\n",
        " A^k = \\sum_{j=1}^n\\mathbf{u}_j\\mathbf{u}_j^T\\lambda_j^k\n",
        "$$\n",
        "\n",
        "and thus rewrite Equation {numref}`eigcen` as\n",
        "\n",
        "$$\n",
        "\\mathbf{e}&= \\displaystyle \\left[\n",
        "\\sum_{k=1}^\\infty{\\alpha^{k-1}\n",
        "\\left(\\sum_{j=1}^n\\mathbf{u}_j\\mathbf{u}_j^T\\lambda_j^k\n",
        "\\right)}\\right]\\mathbf{1}\\\\\n",
        "&=\\displaystyle\\frac{1}{\\alpha}\\left[\\sum_{j=1}^n\\sum_{k=1}^\\infty\n",
        "\\left(\\alpha\\lambda_j\\right)^k\\mathbf{u}_j\\mathbf{u}_j^T\\right]\\mathbf{1},\\\\ \\label{eqn:eigcen_line3}\n",
        "&=\\frac{1}{\\alpha}\\left[\\sum_{j=1}^n\\frac{1}{1 - \\alpha\\lambda_j}\\mathbf{u}_j\\mathbf{u}_j^T\\right]\\mathbf{1}.\n",
        "$$\n",
        "\n",
        "The last line follows since $\\displaystyle\\sum_{k=1}^\\infty\n",
        "\\left(\\alpha\\lambda_j\\right)^k$ is a geometric series.\n",
        "\n",
        "Letting $\\alpha\\to 1/\\lambda_1$ from below the expression in {numref}`eigcen_line3` approaches the eigenvector associated with the largest eigenvalue of the adjacency matrix:\n",
        "\n",
        "$$\\displaystyle\\lim_{\\alpha\\to 1/\\lambda_1}\\mathbf{e} = \\mathbf{u}_1.$$\n",
        "\n",
        "The $i$th entry of the principal eigenvector of the adjacency matrix is known as the eigenvector centrality of node $i$.\n",
        "\n",
        "\\\n",
        "**Remarks**: (1) Typically we normalise $\\mathbf{u}_1$ so that it has length one. (2) By the Perron-Frobenius theorem we can always find a $\\mathbf{u}_1$ with all positive entries.\n",
        "\n",
        "\\\n",
        "**Exercise**: Prove that the expression in Equation {numref}`eigcen_line3` approaches the principal eigenvector $\\mathbf{u}_1$ of $A$ as $\\alpha\\to 1/\\lambda_1$.\n",
        "\n",
        "\\\n",
        "The eigenvector centrality scores for the networks in {numref}`centrality1` and {numref}`centrality2` are given by\n",
        "\n",
        "$$\n",
        " \\mathbf{u}_1 = [0.4735, \\mathbf{0.6359}, 0.4735, 0.2714, 0.2714]\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        " \\mathbf{u}_1 = [0.14, 0.27, 0.27, 0.07, 0.29, \\mathbf{0.55}, 0.14, 0.27, 0.27, 0.52, 0.13]\n",
        "$$\n",
        "\n",
        "respectively. Note that for network in {numref}`centrality2` we ignore the directionality of the network (i.e. we consider it as a simple undirected network), although we could have considered an extension of the eigenvector centrality to directed networks by looking at both the left and right eigenvectors - see PageRank below. Importantly, when direction is ignored node 10 is deemed much more important than it is by the Katz index.\n",
        "\n",
        "```{figure} ../../images/MacaqueExample.png\n",
        "---\n",
        "height: 350px\n",
        "name: MacaqueExample\n",
        "---\n",
        "(a) A MATLAB spy plot of the undirected adjacency matrix for the Macaque cortical network. (b) Degree, Katz and eigenvector centrality for the Macaque cortical network; note that nodes are ordered according to eigenvector centrality scores.\n",
        "```\n",
        "\n",
        "A plot highlighting some of the differences between the centrality measures discussed above is given in {numref}`MacaqueExample`. Here we consider the cortical network of the Macaque monkey - 47 nodes denoting distinct cortical areas and 626 edges denoting physical links between these areas. This network is directed but in the calculation of eigenvector and degree centralities we treated the network as undirected. All three centrality measures follow roughly the same trend, however, Katz centrality ($\\alpha = 0.05$) and degree centrality seem to more strongly correlated for this network, which is perhaps not too surprising given the small value of the attenuation factor.\n",
        "\n",
        "### PageRank\n",
        "Closely related to the above concepts is that of the PageRank algorithm that Google employs to rank web pages. Google models the World Wide Web (WWW) as a network $N = (V, E)$ such that each node describes a webpage and a directed edge is placed between pairs of webpages if a hyperlink exists linking one page to the other. In addition, edges are weighted according to the out-degree of each node, which leads to a weighted adjacency matrix of the form\n",
        "\n",
        "$$\n",
        " H = D_\\mathrm{out}^{-1}A,\\qquad (\\text{here } D_\\mathrm{out} = \\mathrm{diag}\\left(k_1^\\mathrm{out},k_2^\\mathrm{out},\\ldots, k_n^\\mathrm{out}\\right))\n",
        "$$\n",
        "\n",
        "which is a row stochastic matrix termed the *hyperlink matrix*. Note that the above weighted network defines a Markov process, and the idea behind the PageRank algorithm is to rank webpages based upon the amount of time a random surfer (following this probability structure) would spend at each page. However, a number of issues arise due to the structure of the WWW, such as the existence of so-called \"dangling nodes\" which are web pages with no out-going links - such pages act as dead-ends from which the random surfer cannot escape. For this reason the actual *Google matrix* is a modified version of Equation {numref}`google` that avoids issues such as these, and is given by\n",
        "\n",
        "$$\n",
        " G = \\alpha S + \\frac{1-\\alpha}{n}\\mathbf{1}\\mathbf{1}^T.\n",
        "$$\n",
        "\n",
        "where $S = H + \\mathbf{a}(1/n\\mathbf{1}^T)$, where $a_i=1$ if page $i$ is \"dangling\", and $\\mathbf{1}_i=1, \\forall i$. Importantly, the resulting matrix is both stochastic and irreducible.\n",
        "\n",
        "```{figure} ../../images/GoogleExample.png\n",
        "---\n",
        "height: 350px\n",
        "name: googleexample\n",
        "---\n",
        "A directed network on 6 nodes.\n",
        "```\n",
        "\n",
        "One problem with the above matrix representation, which is particularly pertinent for a network the size of the WWW, is that it results in a completely dense matrix, which is very bad from a computational point of view. Fortunately, $G$ can be rewritten as a \\emph{rank-one update} to the sparse hyperlink matrix $H$ as follows\n",
        "\n",
        "$$\n",
        " G &= \\alpha\\left(H + 1/n\\mathbf{a}\\mathbf{1}^T\\right) + (1-\\alpha)1/n\\mathbf{1}\\mathbf{1}^T\\\\\n",
        "   &= \\alpha H + (\\alpha\\mathbf{a}+(1-\\alpha)\\mathbf{1})1/n\\mathbf{1}^T.\n",
        "$$\n",
        "\n",
        "As an example, consider the network in Figure \\ref{fig:googleexample}. Setting $\\alpha = 0.9$ results in the following Google matrix\n",
        "\n",
        "$$\n",
        " G &= 0.9H + (0.9      \n",
        "      \\left(\n",
        "       \\begin{array}{c}\n",
        "       0 \\\\\n",
        "       1 \\\\\n",
        "       0 \\\\\n",
        "       0 \\\\\n",
        "       0 \\\\\n",
        "       0 \\\\\n",
        "      \\end{array}\n",
        "      \\right) + 0.1      \n",
        "     \\left(\n",
        "      \\begin{array}{c}\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      1 \\\\\n",
        "      \\end{array}\n",
        "     \\right))1/6\\left(\n",
        "      \\begin{array}{cccccc}\n",
        "      1&1&1&1&1&1\\\\      \\end{array}\n",
        "      \\right)\\\\\n",
        "   &\\\\   \n",
        "   &= \\left(\n",
        "      \\begin{array}{cccccc}\n",
        "      1/60  & 7/15  & 7/15 & 1/60  & 1/60  & 1/60\\\\\n",
        "      1/6   &  1/6  & 1/6  & 1/6   & 1/6   & 1/6 \\\\\n",
        "      19/60 & 19/60 & 1/60 & 1/60  & 19/60 & 1/60\\\\\n",
        "      1/60  & 1/60  & 1/60 & 1/60  & 7/15  & 7/15\\\\\n",
        "      1/60  & 1/60  & 1/60 & 7/15  & 1/60  & 7/15\\\\\n",
        "      1/60  & 1/60  & 1/60 & 11/12 & 1/60  & 1/60\\\\  \n",
        "      \\end{array}\n",
        "      \\right)\n",
        "$$\n",
        "\n",
        "Google's PageRank vector is the \"stationary\" vector of $G$ and is given by\n",
        "\n",
        "$$\n",
        "\\mathbf{\\pi}^T = \\left(\n",
        "      \\begin{array}{cccccc}\n",
        "      0.03721&0.05396&0.04151&0.3751&0.206&0.2862\\\\      \\end{array}\n",
        "      \\right)\n",
        "$$\n",
        "\n",
        "The above vector is guaranteed to exist for the matrix $G$, however, it does not in general exist for the hyperlink matrix $H$. According to the PageRank scores, nodes 4 and 6 are the most important, whilst node 1 is the least important - PageRank measures the importance of a node in terms of how \"important\" the nodes pointing at it are.  "
      ]
    }
  ]
}